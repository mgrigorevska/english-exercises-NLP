## –∏–º–ø–æ—Ä—Ç—ã

import nltk
import numpy as np
import pandas as pd
import pyinflect
import random
import re
import spacy
import streamlit as st

from io import StringIO, BytesIO
from gtts import gTTS
from nltk.tokenize import sent_tokenize
from pyinflect import getAllInflections, getInflection

nltk.download('punkt')
nltk.download('wordnet')

random.seed(42)

###################### –§–£–ù–ö–¶–ò–ò #########################

## –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞

def text_len_check(text):
    if len(text) <= 10000:
        if st.button('–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—Å—Ç', key='len_check'):
            st.write(text)
        text = text.replace('\n', ' ')
    else:
        st.write('–¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–Ω–µ–µ 10000 —Å–∏–º–≤–æ–ª–æ–≤')

## –≤—ã–±–æ—Ä —á–∏—Å–ª–∞ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π

def ex_num_slider(df):
    if len(df) == 0:
        st.write('')
        ex_num_option = 0
    else:
        with st.sidebar:
            ex_num_option = st.slider('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:', 1,
                                      len(df), 
                                      len(df) // 3,            # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç—Ä–µ—Ç—å —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π                     
                                      key='slider')
    return ex_num_option

## —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤

def option_check(option, corr_counter, answ, i):
    if option == '':
        st.write('')
    elif option.lower() == answ.lower():
        st.success('–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç', icon='‚úÖ')
        corr_counter += 1
    else:
        st.error('–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑', icon='‚ùå')
        if st.button('–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç–≤–µ—Ç', key='show_answ'+str(i)):
            st.write(answ)
    return corr_counter

## info 

def info_func(ex_num_option):
    if ex_num_option == 0:
        st.info('ü§î –ü–æ—Ö–æ–∂–µ, —Ç—É—Ç –Ω–∏—á–µ–≥–æ –Ω–µ—Ç. –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã: –≤—ã–±—Ä–∞–Ω–æ –Ω—É–ª–µ–≤–æ–µ —á–∏—Å–ª–æ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π, –∏–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥—Ä—É–≥–æ–π —Ç–µ–∫—Å—ÇüòÖ')

## –¥—ã—Ä–∫–∞ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ c selectbox –∏ —Å—á–µ—Ç—á–∏–∫–æ–º

def gap_func(df, ex_num_option):

    corr_counter = 0
    info_func(ex_num_option)

    for i in range(ex_num_option):
        
        splitted = df.sent[i].split(df.answ[i])    # –¥–µ–ª–∞–µ–º —Å–ø–ª–∏—Ç –ø–æ –æ—Ç–≤–µ—Ç—É, –¥–æ–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∑–∂–µ
        st.write('______'.join(splitted))
        option = st.selectbox('–í—ã–±–µ—Ä–∏ –æ—Ç–≤–µ—Ç: ', (df.answ_list[i]), key='gap'+str(i))
        corr_counter = option_check(option, corr_counter, df.answ[i], i)
        
        st.divider()

    return corr_counter         

## –≤—ã–≤–æ–¥ –∫–æ–ª-–≤–∞ –≤–µ—Ä–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤

def answ_counter_func(corr_counter, ex_num_option):
    with st.sidebar:
        st.write('–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã:', corr_counter, '–∏–∑', ex_num_option)

## —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ –Ω–∞ –≤—Ä–µ–º—è –≥–ª–∞–≥–æ–ª–æ–≤

def verb_func(df):
    for i in range(len(df)):
        doc = nlp(df.sent[i])

        for token in doc:
            if token.pos_ == 'VERB':
                df.answ[i] = token.text
                df.answ_list[i] = token._.inflect('VB')  

    df = df.dropna().reset_index(drop=True)
    answ_list = set()
    forms_list = ['VBZ', 'VBG', 'VBD', 'VBP']

    for i in range(len(df)):

        answ_list = {list(getInflection(df.answ_list[i].lower(), tag=form))[0] for form in forms_list}
        answ_list.add('had ' + list(getInflection(df.answ_list[i].lower(), tag='VBN'))[0])
        df.answ_list[i] = list(answ_list)
        df.answ_list[i].insert(0, '')

    ex_num_option = ex_num_slider(df)
    corr_counter = gap_func(df, ex_num_option)
    answ_counter_func(corr_counter, ex_num_option)


## —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ –Ω–∞ —Ñ–æ—Ä–º—É –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö


def adj_func(df):
    for i in range(len(df)):
        doc = nlp(df.sent[i])
        for token in doc:
            if token.pos_ == 'ADJ':
                df.answ[i] = token.text
                df.answ_list[i] = token._.inflect('JJ')

    df = df.dropna().reset_index(drop=True)

    for i in range(len(df)):
        answ_list = set()
        answ_list.add(list(getInflection(df.answ_list[i], tag='JJ'))[0].lower())
        answ_list.add(list(getInflection(df.answ_list[i], tag='JJR'))[0].lower())
        answ_list.add('the ' + list(getInflection(df.answ_list[i], tag='JJS'))[0].lower())
        answ_list.add(df.answ[i].lower())

        df.answ_list[i] = list(answ_list)
        df.answ_list[i].insert(0, '')

    ex_num_option = ex_num_slider(df)
    corr_counter = gap_func(df, ex_num_option)
    answ_counter_func(corr_counter, ex_num_option)

## –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏

def word_order_func(df):
    for i in range(len(df)):

        df.answ[i] = (df.sent[i].replace('\"', '').split())
        df.answ_list[i] = df.sent[i].replace('\"', '').split()

        if len(df.answ_list[i]) > 7:   # –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∏ –∫—Ä–∞—Å–æ—Ç—ã           
            df.answ[i] = None

    df = df.dropna().reset_index(drop=True)
    ex_num_option = ex_num_slider(df)
    corr_counter = 0
    info_func(ex_num_option)

    for i in range(ex_num_option):

        random.shuffle(df.answ_list[i])
        options = st.multiselect('–°–æ—Å—Ç–∞–≤—å—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:', df.answ_list[i]) # –≤—ã–±–æ—Ä —Å–ª–æ–≤ –≤ –º—É–ª—å—Ç–∏—Å–µ–ª–µ–∫—Ç
        
        if options == []:                                                 # –∏ —Å—á–µ—Ç—á–∏–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            st.write('')

        elif options == df.answ[i]:
            st.success('–í–µ—Ä–Ω–æ!', icon='‚úÖ')
            corr_counter +=1

        else:
            st.error('–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑', icon='‚ùå')
            if st.button('–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç–≤–µ—Ç', key='show_answ'+str(i)):
                st.write(' '.join(df.answ[i]))

        st.divider()

    return corr_counter, ex_num_option


## —É–ø—Ä–∞–∂–µ–Ω–∏–µ –∞—É–¥–∏–æ 

def audio_func(df):
    for i in range(len(df)):

        doc = nlp(df.sent[i])
        for token in doc:

            if (token.pos_ == 'NOUN') or (token.pos_ == 'ADJ'): # –≤—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∏–ª–∏ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ
                df.answ[i] = token.text
                df.answ_list[i] = token.text

    df = df.dropna().reset_index(drop=True)
    ex_num_option = ex_num_slider(df)
    corr_counter = 0
    info_func(ex_num_option)

    for i in range(ex_num_option):

        sound_file = BytesIO()
        audio = gTTS(text = df.sent[i], lang='en')
        audio.write_to_fp(sound_file)
        st.audio(sound_file)

        splitted = df.sent[i].split(df.answ[i])
        st.write('______'.join(splitted))
        option = st.text_input('–ù–∞–ø–∏—à–∏—Ç–µ —Å–≤–æ–π –æ—Ç–≤–µ—Ç:', '', key='fill_the_gap'+str(i))
        corr_counter = option_check(option, corr_counter, df.answ[i], i)

        st.divider()

    answ_counter_func(corr_counter, ex_num_option)

###################### –í–´–ü–û–õ–ù–ï–ù–ò–ï #########################

st.set_page_config(page_title='SEGen', page_icon=':abc:')

st.title('–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–æ—Å—Ç—ã—Ö —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π –ø–æ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º—É —è–∑—ã–∫—É')
st.caption('–î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–ª–∏ –≤–≤–µ–¥–∏ —Å–≤–æ–π —Ç–µ–∫—Å—Ç –∏ –Ω–∞–∂–º–∏ Enter')

with st.sidebar:
    st.subheader('–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:')

## –∑–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞

text = ''
file = st.file_uploader('–í—ã–±—Ä–∞—Ç—å —Ñ–∞–π–ª(.txt):')

if file is not None:
    stringio = StringIO(file.getvalue().decode("utf-8"))
    text = stringio.read()
    text_len_check(text)

else:
    text = st.text_input('–í–≤–µ—Å—Ç–∏ —Å–≤–æ–π —Ç–µ–∫—Å—Ç:', '', max_chars=10000, key='text_input', help='–õ—É—á—à–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ 10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –±–æ–ª–µ–µ')
    if text is not None:
        text_len_check(text)

## —Å–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ 

sentences = sent_tokenize(text)     # —Ä–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
df = []

for sent in sentences:
    df.append(sent)

df = pd.DataFrame(df).rename(columns={0: 'sent'})
df['answ'] = np.nan         
df['answ_list'] = np.nan        # –∑–∞–ø–æ–ª–Ω—è–µ–º —Å—Ç–æ–ª–±—Ü—ã –ø—É—Å—Ç—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏

nlp = spacy.load('en_core_web_sm')


## –≤—ã–±–æ—Ä —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è


with st.sidebar:
    ex_option = st.radio('–¢–∏–ø —É–ø—Ä–∞–∂–µ–Ω–∏—è:',
        ('–í—Ä–µ–º–µ–Ω–∞ –≥–ª–∞–≥–æ–ª–æ–≤', '–§–æ—Ä–º–∞ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö',
         '–ü–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏', '–ê—É–¥–∏–æ'), key='ex_type')

st.write('–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ:  ', ex_option)


## –≤—ã–±–æ—Ä –≤—Ä–µ–º–µ–Ω–∞ –≥–ª–∞–≥–æ–ª–æ–≤

if ex_option == '–í—Ä–µ–º–µ–Ω–∞ –≥–ª–∞–≥–æ–ª–æ–≤':
    st.caption('–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–±–µ–ª –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏, –≤—ã–±—Ä–∞–≤ –≤–∞—Ä–∏–∞–Ω—Ç –∏–∑ –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞')

    verb_func(df)


## –≤—ã–±–æ—Ä —Ñ–æ—Ä–º–∞ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö

if ex_option == '–§–æ—Ä–º–∞ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö':
    st.caption('–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–±–µ–ª –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏, –≤—ã–±—Ä–∞–≤ –≤–∞—Ä–∏–∞–Ω—Ç –∏–∑ –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞')

    adj_func(df)


## –≤—ã–±–æ—Ä –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤

if ex_option == '–ü–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏':

    st.caption('–°–æ—Å—Ç–∞–≤—å—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ, –≤—ã–±—Ä–∞–≤ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ –≤—ã–ø–∞–¥–∞—é—â–µ–≥–æ —Å–ø–∏—Å–∫–∞')

    corr_counter, ex_num_option = word_order_func(df)
    answ_counter_func(corr_counter, ex_num_option)


## –≤—ã–±–æ—Ä –∞—É–¥–∏–æ

if ex_option == '–ê—É–¥–∏–æ':

    st.caption('–ü—Ä–æ—Å–ª—É—à–∞–π—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–±–µ–ª, –Ω–∞–ø–∏—Å–∞–≤ —Å–ª–æ–≤–æ –≤ —è—á–µ–π–∫–µ')

    audio_func(df)














































